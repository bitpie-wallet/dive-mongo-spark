1.intellij setting: https://weilu2.github.io/2018/11/16/%E9%85%8D%E7%BD%AE-Intellij-Idea-%E5%92%8C-Sbt-%E5%BC%80%E5%8F%91%E3%80%81%E6%89%93%E5%8C%85%E3%80%81%E8%BF%90%E8%A1%8C-Spark-%E7%A8%8B%E5%BA%8F/
2.intellij install:
$ brew update                             # Fetch latest version of homebrew and formula.
$ brew tap homebrew/cask                  # Tap the Homebrew/Cask repository from Github using HTTPS.
$ brew search intellij-idea-ce            # Searches all known Casks for a partial or exact match.
$ brew info --cask intellij-idea-ce       # Displays information about the given Cask
$ brew install --cask intellij-idea-ce    # Install the given cask.
$ brew cleanup
3.sbt install  brew install sbt



mongo connector:
https://www.mongodb.com/docs/spark-connector/master/scala-api/


教程：
https://www.learningjournal.guru/courses/spark/spark-foundation-training/how-to-create-and-submit-spark-applications/

部署命令：

sbt clean package
spark-submit --packages org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 --master local --class dive.address.SparkTestApp target/scala-2.12/dive-mongo_2.12-0.1.0-SNAPSHOT.jar ~/work/bitcore/test.csv

去除重复数据

https://kontext.tech/article/660/remove-duplicated-rows-from-spark-dataframe


 brew services start  mongodb/brew/mongodb-community



